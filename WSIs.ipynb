{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBWpVW_7s95K",
    "outputId": "c0539f62-1b2e-4109-d7be-b2b5d846b487"
   },
   "outputs": [],
   "source": [
    "# !apt update && apt install -y openslide-tools\n",
    "# !pip install openslide-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIeT5rMgXjbZ",
    "outputId": "1785422f-8615-45dc-cc4b-80a1fe94a122"
   },
   "outputs": [],
   "source": [
    "# !rm -r \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP\"\n",
    "# !git clone https://github.com/frpnz/teaching-MLinAPP.git \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJMwibgmtReE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openslide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = 'true'\n",
    "import matplotlib.pyplot as plt\n",
    "import openslide.deepzoom as dz\n",
    "from sklearn import model_selection\n",
    "rootdir_wsi = \"/space/ponzio/CRC_ROIs_4_classes/\"\n",
    "rootdir_src = \"/space/ponzio/teaching-MLinAPP/src/\"\n",
    "sys.path.append(rootdir_src)\n",
    "from resnet import ResNet\n",
    "from dataset_wsi import DatasetWSI\n",
    "# ----------------------\n",
    "tile_size = 300\n",
    "overlap = 6\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "class_dict = {\n",
    "    \"AC\": 0,\n",
    "    \"AD\": 1,\n",
    "    \"H\": 2\n",
    "}\n",
    "checkpoint_filepath = './models_crc/checkpoint_crc_3_cls'                                                                                                                                                             \n",
    "# ----------------------\n",
    "num_classes = len(class_dict.keys())\n",
    "wsi_file_paths = glob(os.path.join(rootdir_wsi, '*.svs'))\n",
    "df = pd.DataFrame([os.path.basename(slide).split('.')[0].split('_') for slide in wsi_file_paths], columns=[\"Patient\",\n",
    "                                                                                                           \"Type\",\n",
    "                                                                                                           \"Sub-type\",\n",
    "                                                                                                           \"Dysplasia\",\n",
    "                                                                                                           \"#-Annotation\"])\n",
    "df['Path'] = wsi_file_paths\n",
    "wsi_file_paths = df['Path']\n",
    "wsi_labels = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "dataset_train = DatasetWSI(wsi_file_paths,\n",
    "                           wsi_labels,\n",
    "                           class_dict,\n",
    "                           batch_size=batch_size,\n",
    "                           tile_size=tile_size,\n",
    "                           overlap=6).make_dataset()\n",
    "for batch_x, batch_y in dataset_train.take(1):\n",
    "    input_shape = batch_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWmrhB7dxdxM"
   },
   "outputs": [],
   "source": [
    "inv_class_dict = {v: k for k, v in class_dict.items()}\n",
    "for batch_x, batch_y in dataset_train.take(2):\n",
    "    fig, ax = plt.subplots(5, 5, figsize=(18, 18))\n",
    "    ax = ax.ravel()\n",
    "    j = 0\n",
    "    for image, label in zip(batch_x[:25], batch_y[:25]):\n",
    "        label = label.numpy()\n",
    "        img = image.numpy()\n",
    "        input_shape = img.shape\n",
    "        ax[j].imshow(img)\n",
    "        ax[j].axis('off')\n",
    "        ax[j].set_title(\"Class: {} - {}\".format(inv_class_dict[int(np.argmax(label))], label))\n",
    "        j += 1\n",
    "fig.savefig(\"images.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./crc_images/train\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=64)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=64)\n",
    "\n",
    "data_dir = \"./crc_images/test\"\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUi4mQXgdQLr"
   },
   "outputs": [],
   "source": [
    "augmentation_block = [\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=(-0.05, -0.15),\n",
    "        width_factor=(-0.05, -0.15)),\n",
    "    tf.keras.layers.RandomRotation(0.3),\n",
    "]\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x =  tf.keras.applications.resnet50.preprocess_input(inputs)\n",
    "x = tf.keras.layers.Resizing(64, 64)(x)\n",
    "for layer in augmentation_block:\n",
    "    x = layer(x, training=False)\n",
    "base_model = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\")\n",
    "for j, layer in enumerate(base_model.layers[:100]):\n",
    "    layer.trainable = False\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "# model = ResNet((input_shape[0], input_shape[1]), \n",
    "#                num_classes=num_classes, \n",
    "#                augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(                                                                                                                                          \n",
    "    filepath=checkpoint_filepath,                                                                                                                                                                        \n",
    "    save_weights_only=True,                                                                                                                                                                              \n",
    "    monitor='accuracy',                                                                                                                                                                              \n",
    "    mode='max',                                                                                                                                                                                          \n",
    "    save_best_only=True)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='accuracy',\n",
    "    factor=0.1,\n",
    "    patience=7,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m549m0Td__Zf"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWJzv7-mAGYu"
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=train_ds,\n",
    "          epochs=epochs, callbacks=[checkpoint_callback, lr_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(results[1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WSIs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "",
   "toc_cell": true,
   "toc_position": {
    "height": "47.7167px",
    "left": "980px",
    "top": "54px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
