{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBWpVW_7s95K",
    "outputId": "c0539f62-1b2e-4109-d7be-b2b5d846b487"
   },
   "outputs": [],
   "source": [
    "# !apt update && apt install -y openslide-tools\n",
    "# !pip install openslide-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIeT5rMgXjbZ",
    "outputId": "1785422f-8615-45dc-cc4b-80a1fe94a122"
   },
   "outputs": [],
   "source": [
    "# !rm -r \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP\"\n",
    "# !git clone https://github.com/frpnz/teaching-MLinAPP.git \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aJMwibgmtReE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openslide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = 'true'\n",
    "import matplotlib.pyplot as plt\n",
    "import openslide.deepzoom as dz\n",
    "from sklearn import model_selection\n",
    "rootdir_wsi = \"/space/ponzio/CRC_WSIs/\"\n",
    "rootdir_src = \"/space/ponzio/teaching-MLinAPP/src/\"\n",
    "sys.path.append(rootdir_src)\n",
    "from resnet import ResNet\n",
    "from wsi_utils import DatasetManager\n",
    "from sklearn import model_selection\n",
    "# ----------------------\n",
    "tile_size = 1000\n",
    "tile_new_size = 112\n",
    "overlap = 1\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "batch_size = 16\n",
    "channels = 3\n",
    "class_dict = {\n",
    "    \"H\": 0,\n",
    "    \"NH\": 1\n",
    "}\n",
    "checkpoint_filepath = './models_crc/checkpoint_crc_3_cls'                                                                                                                                                             \n",
    "# ----------------------\n",
    "input_shape = (tile_new_size, tile_new_size, channels)\n",
    "num_classes = len(class_dict.keys())\n",
    "wsi_file_paths_test = glob(os.path.join(rootdir_wsi, '*.svs'))\n",
    "wsi_labels_numerical_test = [0]*len(wsi_file_paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "Found in total:\n",
      " 1750 tiles\n",
      " belonging to 1 slides\n",
      "**************************\n",
      "WARNING:tensorflow:AutoGraph could not transform <function DatasetManager.make_dataset.<locals>.<lambda> at 0x7f4bec7ab378> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DatasetManager.make_dataset.<locals>.<lambda> at 0x7f4bec7ab378>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function DatasetManager.make_dataset.<locals>.<lambda> at 0x7f4bec7ab378> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DatasetManager.make_dataset.<locals>.<lambda> at 0x7f4bec7ab378>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "dataset_manager_test = DatasetManager([wsi_file_paths_test[0]],\n",
    "                                      [wsi_labels_numerical_test[0]],\n",
    "                                      tile_size=tile_size,\n",
    "                                      tile_new_size=tile_new_size,\n",
    "                                      channels=channels,\n",
    "                                      batch_size=batch_size)\n",
    "dataset_test = dataset_manager_test.make_dataset(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_class_dict = {v: k for k, v in class_dict.items()}\n",
    "for batch_x, batch_y in dataset_test.take(1):\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(15, 15))\n",
    "    ax = ax.ravel()\n",
    "    j = 0\n",
    "    for image, label in zip(batch_x[:16], batch_y[:16]):\n",
    "        label = label.numpy()\n",
    "        img = image.numpy()\n",
    "        ax[j].imshow(img)\n",
    "        ax[j].axis('off')\n",
    "        ax[j].set_title(\"Class: {} - {}\\nshape:{}\".format(inv_class_dict[int(np.argmax(label))], label, image.shape))\n",
    "        j += 1\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"test_images.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(list(dataset_test)))\n",
    "# tile_placeholders = dataset_manager_test.get_tile_placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"./crc_images/train\"\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     data_dir,\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"training\",\n",
    "#     label_mode=\"categorical\",\n",
    "#     seed=123,\n",
    "#     image_size=(input_shape[0], input_shape[1]),\n",
    "#     batch_size=64)\n",
    "\n",
    "# val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     data_dir,\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"validation\",\n",
    "#     label_mode=\"categorical\",\n",
    "#     seed=123,\n",
    "#     image_size=(input_shape[0], input_shape[1]),\n",
    "#     batch_size=64)\n",
    "\n",
    "# data_dir = \"./crc_images/test\"\n",
    "# test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     data_dir,\n",
    "#     label_mode=\"categorical\",\n",
    "#     seed=123,\n",
    "#     image_size=(input_shape[0], input_shape[1]),\n",
    "#     batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUi4mQXgdQLr"
   },
   "outputs": [],
   "source": [
    "augmentation_block = [\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=(-0.05, -0.15),\n",
    "        width_factor=(-0.05, -0.15)),\n",
    "    tf.keras.layers.RandomRotation(0.3),\n",
    "]\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x =  tf.keras.applications.resnet50.preprocess_input(inputs)\n",
    "for layer in augmentation_block:\n",
    "    x = layer(x, training=False)\n",
    "base_model = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\")\n",
    "for j, layer in enumerate(base_model.layers[:100]):\n",
    "    layer.trainable = False\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "# model = ResNet((input_shape[0], input_shape[1]), \n",
    "#                num_classes=num_classes, \n",
    "#                augment=True)\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(                                                                                                                                          \n",
    "    filepath=checkpoint_filepath,                                                                                                                                                                        \n",
    "    save_weights_only=True,                                                                                                                                                                              \n",
    "    monitor='accuracy',                                                                                                                                                                              \n",
    "    mode='max',                                                                                                                                                                                          \n",
    "    save_best_only=True)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='accuracy',\n",
    "    factor=0.1,\n",
    "    patience=7,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    ")\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m549m0Td__Zf"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWJzv7-mAGYu"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset_train, epochs=epochs, callbacks=[checkpoint_callback, lr_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(results[1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WSIs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "",
   "toc_cell": true,
   "toc_position": {
    "height": "47.7167px",
    "left": "980px",
    "top": "54px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
