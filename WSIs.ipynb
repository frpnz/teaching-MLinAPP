{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBWpVW_7s95K",
        "outputId": "c0539f62-1b2e-4109-d7be-b2b5d846b487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 0 B/88.7 kB \u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 88.7 kB/88.7 kB 100%] [Waiting for header\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,660 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,484 kB]\n",
            "Fetched 4,395 kB in 4s (1,188 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "60 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from openslide-python) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!apt update && apt install -y openslide-tools\n",
        "!pip install openslide-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP\"\n",
        "!git clone https://github.com/frpnz/teaching-MLinAPP.git \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIeT5rMgXjbZ",
        "outputId": "1785422f-8615-45dc-cc4b-80a1fe94a122"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 69 (delta 30), reused 54 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (69/69), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aJMwibgmtReE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import openslide\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import openslide.deepzoom as dz\n",
        "ROOTDIR_WSI = \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/CRC_ROIs_2_classes\"\n",
        "ROOTDIR_DATA = \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/\"\n",
        "ROOTDIR_SRC = \"/content/drive/MyDrive/Teaching&Thesis/Teaching_dataset/teaching-MLinAPP/src\"\n",
        "sys.path.append(ROOTDIR_DATA)\n",
        "sys.path.append(ROOTDIR_SRC)\n",
        "tileSize = 500\n",
        "overlap = 6\n",
        "input_shape = (512, 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from resnet import ResNet"
      ],
      "metadata": {
        "id": "reFX3FsZZW_4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GaRdHW8x19XU"
      },
      "outputs": [],
      "source": [
        "files = glob(os.path.join(ROOTDIR_WSI, '*.svs'))\n",
        "openSlideObjects = [(openslide.OpenSlide(slide), os.path.basename(slide).split('_')[1]) for slide in files]\n",
        "deepZoomObjects = [(dz.DeepZoomGenerator(slide, tile_size=tileSize, overlap=overlap, limit_bounds=True),label) for slide, label in openSlideObjects]\n",
        "deepZoomObjects = [(slide, label, slide.get_tile(10,(0,0))) for slide, label in deepZoomObjects]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(deepZoomObjects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEMxRJatl159",
        "outputId": "8c790ac7-5143-49e2-a40c-9026ddfbd17e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iIg5Jbwh3zxj"
      },
      "outputs": [],
      "source": [
        "from math import floor\n",
        "\n",
        "classDict = {\n",
        "    'AC':0,\n",
        "    'H':1,\n",
        "}\n",
        "\n",
        "def createTilePlaceholders(deepZoomObject,label,level,preview):\n",
        "    if level>=deepZoomObject.level_count:\n",
        "        raise(RuntimeError('Requested level is not available'))\n",
        "\n",
        "    out=[]\n",
        "    preview = tf.reshape(tf.cast(preview.getdata(),dtype=tf.uint8),(preview.size[0],preview.size[1],3))\n",
        "    preview = tf.image.convert_image_dtype(preview,dtype=tf.float32)\n",
        "    previewScale = 2**(level-10)\n",
        "\n",
        "    for i in range(deepZoomObject.level_tiles[level][0]):\n",
        "        for j in range(deepZoomObject.level_tiles[level][1]):\n",
        "            tmp={\n",
        "                'deepZoomObject':deepZoomObject,\n",
        "                'level':level,\n",
        "                'coordinates':(i,j),\n",
        "                'label':label}\n",
        "            position = (floor(i*tileSize/previewScale),floor(j*tileSize/previewScale),\n",
        "                        floor(i + 1*tileSize/previewScale), floor(j + 1*tileSize/previewScale))\n",
        "            crop = preview[position[0]:position[1],position[2]:position[3]]\n",
        "            if tf.reduce_mean(tf.math.reduce_std(crop,axis=-1))>0.02:\n",
        "                out.append(tmp)\n",
        "    return out\n",
        "\n",
        "tilePlaceholders = [createTilePlaceholders(slide,\n",
        "                                           label,\n",
        "                                           slide.level_count-2,\n",
        "                                           preview) for slide, label, preview in deepZoomObjects]\n",
        "tilePlaceholders = [item for sublist in tilePlaceholders for item in sublist]\n",
        "\n",
        "def toImage(x):\n",
        "    tile = tilePlaceholders[x.numpy()]\n",
        "    PILObject = tile['deepZoomObject'].get_tile(tile['level'], tile['coordinates'])\n",
        "    imSize = PILObject.size\n",
        "    img = tf.reshape(PILObject.getdata(), (imSize[0], imSize[1], 3))\n",
        "    return tf.image.convert_image_dtype(img, dtype=tf.float32), tf.cast(tf.one_hot(classDict[tile['label']], 2, name='label', axis=-1), tf.float32)\n",
        "\n",
        "def filterWhite(x, label):\n",
        "    if tf.reduce_mean(tf.math.reduce_std(x,axis=-1)) < 0.02:\n",
        "        #tf.print('Skipped (white)')\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def filterBorder(x):\n",
        "    if x.shape[0] != tileSize + 2*overlap or x.shape[1] != tileSize + 2*overlap:\n",
        "        #tf.print('Skipped (border) %d - %d'%(x.shape[0],x.shape[1]))\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def _fixup_shape(image, label):\n",
        "    image.set_shape([512, 512, 3])\n",
        "    label.set_shape([]) # I have 19 classes\n",
        "    # weights.set_shape([None])\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices([i for i in range(len(tilePlaceholders))])\n",
        "dataset = dataset.shuffle(50000)\n",
        "dataset = dataset.map(lambda x: tf.py_function(toImage, [x], Tout=[tf.float32, tf.float32]), num_parallel_calls=8)\n",
        "dataset = dataset.filter(filterWhite)\n",
        "dataset = dataset.filter(lambda x, label: tf.py_function(filterBorder, [x], tf.bool))\n",
        "dataset = dataset.map(_fixup_shape)\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(buffer_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(1):\n",
        "    print(x.shape)\n",
        "    print(y.shape)"
      ],
      "metadata": {
        "id": "BHXLI9HGmH1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_classDict = {v: k for k, v in classDict.items()}\n",
        "for batch_x, batch_y in dataset.take(2):\n",
        "    fig, ax = plt.subplots(5, 5, figsize=(18, 18))\n",
        "    ax = ax.ravel()\n",
        "    j = 0\n",
        "    for image, label in zip(batch_x[:25], batch_y[:25]):\n",
        "        label = label.numpy()\n",
        "        img = image.numpy()\n",
        "        ax[j].imshow(img)\n",
        "        ax[j].axis('off')\n",
        "        ax[j].set_title(\"Class: {}\".format(inv_classDict[int(np.argmax(label))]))\n",
        "        j += 1"
      ],
      "metadata": {
        "id": "OWmrhB7dxdxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_data(image, label, num_classes):\n",
        "#   return tf.cast(image, tf.float32) / 255., tf.one_hot(tf.cast(label, tf.int32), num_classes, name='label', axis=-1)\n",
        "\n",
        "# dataset = dataset.map(lambda x, y: process_data(x, y, 2))\n",
        "data = iter(dataset)"
      ],
      "metadata": {
        "id": "3p9nOsI3h-1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input((512, 512, 3))\n",
        "x = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\")(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(2, activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "ZUi4mQXgdQLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Model(inputs=inputs, outputs=x)"
      ],
      "metadata": {
        "id": "nOFmaBDv_J8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "m549m0Td__Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset)"
      ],
      "metadata": {
        "id": "xWJzv7-mAGYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "WSIs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}